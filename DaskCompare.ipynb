{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ddcd7f",
   "metadata": {},
   "source": [
    "# In this file, dummy csv files(sheets) are compared using pandas, dataframe and datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af2d1d",
   "metadata": {},
   "source": [
    "# Dask is a library used to check the parallel computing and the time taken by files to process the computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbbd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da080cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dask import dataframe as dd\n",
    "import time\n",
    "import os\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f072e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "882e595a",
   "metadata": {},
   "source": [
    "# This module provides an interface to the optional garbage collector. It provides the ability to disable the collector, tune the collection frequency, and set debugging options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8a29f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just in case, to clean up RAM\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cd0a155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape  #--> gives number of rows:cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c170b54",
   "metadata": {},
   "source": [
    "# head () function is used to access the first n rows of a dataframe or series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b2b3c",
   "metadata": {},
   "source": [
    "# Accordingly tail() returns the last n rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b605214c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tran_Id</th>\n",
       "      <th>TranDate</th>\n",
       "      <th>TranAmnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>345</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>956</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>654</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tran_Id    TranDate  TranAmnt\n",
       "0      123  09-02-2022    200000\n",
       "1      345  09-02-2022    300000\n",
       "2      956  09-02-2022    500000\n",
       "3      524  09-02-2022    800000\n",
       "4      654  09-02-2022    200000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee4266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac44d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1792948246002197e-07 GB\n"
     ]
    }
   ],
   "source": [
    "#SIZE OF DATA TO BE IMPORTED\n",
    "print(os.path.getsize(r'C:\\Users\\Dell\\Desktop\\DaskPython\\DaskTest\\dask1.csv')/1024/1024/1024 , \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64dc02ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv without chunks:  0.10313987731933594 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\DaskPython\\DaskTest\\dask1.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv without chunks: \",(end-start),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226431f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb087337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with chunks:  0.0009949207305908203 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "chunk = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\DaskPython\\DaskTest\\dask1.csv',chunksize=1000000)\n",
    "end = time.time()\n",
    "print(\"Read csv with chunks: \",(end-start),\"sec\")\n",
    "pd_df = pd.concat(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c3310b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.io.parsers.TextFileReader"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be465229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Client registers itself as the default Dask scheduler, and so runs all dask collections like dask.array, dask.bag, dask.dataframe and dask.delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4c99f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\distributed\\node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 64980 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://192.168.0.109/5448/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.0.109:64980/status' target='_blank'>http://192.168.0.109:64980/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>7.90 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://192.168.0.109/5448/1' processes=1 threads=4, memory=7.90 GiB>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(processes=False)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df2641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "771cf302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with dask:  0.01399683952331543 sec\n",
      "Dask size: (Delayed('int-ec8ad790-5b96-4e1c-8201-6f2f055dd3be'), 3)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dask_df = dd.read_csv(r'C:\\Users\\Dell\\Desktop\\DaskPython\\DaskTest\\dask1.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")\n",
    "pd_df = dask_df.compute()\n",
    "print(\"Dask size:\", dask_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f1394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e66eb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tran_Id    TranDate  TranAmnt\n",
      "0      123  09-02-2022    200000\n",
      "1      345  09-02-2022    300000\n",
      "2      956  09-02-2022    500000\n",
      "3      524  09-02-2022    800000\n",
      "4      654  09-02-2022    200000\n",
      "5      123  09-02-2022    200000\n",
      "6      345  09-02-2022    300000\n",
      "7      654  09-02-2022    500000\n",
      "8      123  15-02-2022    100000\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\DaskPython\\DaskTest\\dask1.csv')\n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecfb2e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tran_Id    TranDate  TranAmnt\n",
      "0      123  09-02-2022    200000\n",
      "1      345  09-02-2022    260000\n",
      "2      400  15-02-2022    500000\n",
      "3      524  09-02-2022    800000\n",
      "4      654  09-02-2022    200000\n",
      "5      500  09-02-2022    260000\n",
      "6      999  09-02-2022    300000\n",
      "7      210  09-02-2022    700000\n",
      "8      874  15-02-2022    100000\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\DaskPython\\DaskTest\\dask2.csv')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81484ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tran_Id</th>\n",
       "      <th>TranDate_x</th>\n",
       "      <th>TranAmnt_x</th>\n",
       "      <th>TranDate_y</th>\n",
       "      <th>TranAmnt_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>15-02-2022</td>\n",
       "      <td>100000</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>300000</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>300000</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>524</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>800000</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>654</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>654</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>500000</td>\n",
       "      <td>09-02-2022</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tran_Id  TranDate_x  TranAmnt_x  TranDate_y  TranAmnt_y\n",
       "0      123  09-02-2022      200000  09-02-2022      200000\n",
       "1      123  09-02-2022      200000  09-02-2022      200000\n",
       "2      123  15-02-2022      100000  09-02-2022      200000\n",
       "3      345  09-02-2022      300000  09-02-2022      260000\n",
       "4      345  09-02-2022      300000  09-02-2022      260000\n",
       "5      524  09-02-2022      800000  09-02-2022      800000\n",
       "6      654  09-02-2022      200000  09-02-2022      200000\n",
       "7      654  09-02-2022      500000  09-02-2022      200000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1,df2 , on = 'Tran_Id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dd8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4670342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The isin() method checks if the Dataframe contains the specified value(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "533bdade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "3     True\n",
       "4     True\n",
       "5     True\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.apply(tuple,1).isin(df2.apply(tuple,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af58ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tran_Id    TranDate  TranAmnt\n",
      "0      123  09-02-2022    200000\n",
      "3      524  09-02-2022    800000\n",
      "4      654  09-02-2022    200000\n",
      "5      123  09-02-2022    200000 \n",
      " 0.006981849670410156 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = df1[df1.apply(tuple,1).isin(df2.apply(tuple,1))]\n",
    "end = time.time()\n",
    "print (result, '\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19488e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da1a082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tran_Id    TranDate  TranAmnt _merge\n",
      "0      123  09-02-2022    200000   both\n",
      "1      123  09-02-2022    200000   both\n",
      "2      524  09-02-2022    800000   both\n",
      "3      654  09-02-2022    200000   both \n",
      " 0.021940231323242188 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result2 = df1.merge(df2, how= 'inner', indicator = True)\n",
    "end = time.time()\n",
    "print (result2,'\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "45e8d84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tran_Id    TranDate  TranAmnt      _merge\n",
      "2       345  09-02-2022    300000   left_only\n",
      "3       345  09-02-2022    300000   left_only\n",
      "4       956  09-02-2022    500000   left_only\n",
      "7       654  09-02-2022    500000   left_only\n",
      "8       123  15-02-2022    100000   left_only\n",
      "9       345  09-02-2022    260000  right_only\n",
      "10      400  15-02-2022    500000  right_only\n",
      "11      500  09-02-2022    260000  right_only\n",
      "12      999  09-02-2022    300000  right_only\n",
      "13      210  09-02-2022    700000  right_only\n",
      "14      874  15-02-2022    100000  right_only \n",
      " 0.055845022201538086 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result3 = df1.merge(df2, how= 'outer', indicator = True).loc[lambda v :v['_merge'] != 'both']\n",
    "end = time.time()\n",
    "print (result3,'\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c45373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This returns all rows from both tables, join records from the left which have matching keys in the right table.When there is no Matching from any table NaN will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a1675cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tran_Id  TranDate_x  TranAmnt_x  TranDate_y  TranAmnt_y\n",
      "0       123  09-02-2022    200000.0  09-02-2022    200000.0\n",
      "1       123  09-02-2022    200000.0  09-02-2022    200000.0\n",
      "2       123  15-02-2022    100000.0  09-02-2022    200000.0\n",
      "3       345  09-02-2022    300000.0  09-02-2022    260000.0\n",
      "4       345  09-02-2022    300000.0  09-02-2022    260000.0\n",
      "5       956  09-02-2022    500000.0         NaN         NaN\n",
      "6       524  09-02-2022    800000.0  09-02-2022    800000.0\n",
      "7       654  09-02-2022    200000.0  09-02-2022    200000.0\n",
      "8       654  09-02-2022    500000.0  09-02-2022    200000.0\n",
      "9       400         NaN         NaN  15-02-2022    500000.0\n",
      "10      500         NaN         NaN  09-02-2022    260000.0\n",
      "11      999         NaN         NaN  09-02-2022    300000.0\n",
      "12      210         NaN         NaN  09-02-2022    700000.0\n",
      "13      874         NaN         NaN  15-02-2022    100000.0 \n",
      " 0.008977174758911133 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_merge = df1.merge(df2, how = 'outer', left_on = \"Tran_Id\", right_on = \"Tran_Id\")\n",
    "end = time.time()\n",
    "print (data_merge,'\\n',(end-start),'sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26955758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22b7205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tran_Id_x  TranDate_x  TranAmnt  Tran_Id_y  TranDate_y\n",
      "0         123  09-02-2022    200000        123  09-02-2022\n",
      "1         123  09-02-2022    200000        654  09-02-2022\n",
      "2         654  09-02-2022    200000        123  09-02-2022\n",
      "3         654  09-02-2022    200000        654  09-02-2022\n",
      "4         123  09-02-2022    200000        123  09-02-2022\n",
      "5         123  09-02-2022    200000        654  09-02-2022\n",
      "6         345  09-02-2022    300000        999  09-02-2022\n",
      "7         345  09-02-2022    300000        999  09-02-2022\n",
      "8         956  09-02-2022    500000        400  15-02-2022\n",
      "9         654  09-02-2022    500000        400  15-02-2022\n",
      "10        524  09-02-2022    800000        524  09-02-2022\n",
      "11        123  15-02-2022    100000        874  15-02-2022 \n",
      " 0.009974002838134766 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_merge2 = df1.merge(df2, how = 'inner', left_on = \"TranAmnt\", right_on = \"TranAmnt\")\n",
    "end = time.time()\n",
    "print (data_merge2,'\\n',(end-start),'sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc65163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80a281a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare files\n",
    "with open(r'C:\\Users\\Dell\\Desktop\\DaskPython\\DaskTest\\dask1.csv') as t1, open(r'C:\\Users\\Dell\\Desktop\\DaskPython\\DaskTest\\dask2.csv') as t2:\n",
    "    fileone = t1.readlines()\n",
    "    filetwo = t2.readlines()\n",
    "\n",
    "with open('update.csv','w') as outFile:\n",
    "    for line in filetwo:\n",
    "        if line not in fileone:\n",
    "            outFile.write(line)\n",
    "            end = time.time()\n",
    "\n",
    "#update.csv will give difference of both files which is compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ec44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dcf75d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tran_Id  TranDate_x  TranAmnt  TranDate_y\n",
      "0      123  09-02-2022    200000  09-02-2022\n",
      "1      123  09-02-2022    200000  09-02-2022\n",
      "2      524  09-02-2022    800000  09-02-2022\n",
      "3      654  09-02-2022    200000  09-02-2022 \n",
      " 0.00697779655456543 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result3 = pd.merge(df1,df2, on= ['Tran_Id', 'TranAmnt'], how = 'inner')\n",
    "end = time.time()\n",
    "print (result3,'\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67222b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a07e8c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tran_Id    TranDate  TranAmnt\n",
      "0      123  09-02-2022    200000\n",
      "1      123  09-02-2022    200000\n",
      "2      524  09-02-2022    800000\n",
      "3      654  09-02-2022    200000 \n",
      " 0.028254985809326172 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result5 = pd.merge(df1,df2, on= ['TranDate', 'TranAmnt', 'Tran_Id'], how = 'inner')\n",
    "end = time.time()\n",
    "print (result5,'\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb8a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6e522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23601224",
   "metadata": {},
   "source": [
    "# Computing comparisn based on the files received. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "45be2381",
   "metadata": {},
   "source": [
    "First we import the time module to calculate the time.\n",
    "Then we call the csv file as a dataframe by giving the path of the file.\n",
    "The below file is of FICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e31a96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with dask:  0.012938976287841797 sec\n",
      "Dask size: (Delayed('int-536241db-08ce-4e43-ab94-272ea924e6e3'), 7)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dask_df1 = dd.read_csv(r'C:\\Users\\Dell\\Desktop\\New folder\\Test_1\\Test\\df1_out_FICL.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")\n",
    "pd_df = dask_df1.compute()\n",
    "print(\"Dask size:\", dask_df1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a88f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "645d268b",
   "metadata": {},
   "source": [
    "The below file is of SCLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9440f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with dask:  0.01695704460144043 sec\n",
      "Dask size: (Delayed('int-07c685c7-a67f-401b-984c-365d48213831'), 7)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dask_df2 = dd.read_csv(r'C:\\Users\\Dell\\Desktop\\New folder\\Test_1\\Test\\df2_out_SCLM.csv')\n",
    "end = time.time()\n",
    "print(\"Read csv with dask: \",(end-start),\"sec\")\n",
    "pd_df = dask_df2.compute()\n",
    "print(\"Dask size:\", dask_df2.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbe2b8ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ef3d64e0",
   "metadata": {},
   "source": [
    "We then create a dataframe dataf1 to store the csv data into pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4c3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 TRAN_DATE    TRAN_ID               TRAN_REMARKS     ACCOUNTNO  \\\n",
      "0           0  9/2/2022  S85305249                        NaN  0103SLMPSWDL   \n",
      "1           1  9/2/2022  S85305249                        NaN  0103SLMPSWDL   \n",
      "2           2  9/2/2022  S88796439  224500032693//10101170199  0103SLMPSWDL   \n",
      "3           3  9/2/2022  S80939874                        NaN  0103SLMPSWDL   \n",
      "4           4  9/2/2022  S80939874                        NaN  0103SLMPSWDL   \n",
      "\n",
      "     TRANAMOUNT           REFERENCENO  \n",
      "0 -3.192820e+08  OTHERS-P SETT DT01.0  \n",
      "1 -4.042220e+03  OTHERS-P DIFF DT 31.  \n",
      "2 -2.774900e+03                   NaN  \n",
      "3 -6.637716e+06                     -  \n",
      "4 -7.248358e+05                     -  \n"
     ]
    }
   ],
   "source": [
    "dataf1 = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\New folder\\Test_1\\Test\\df1_out_FICL.csv')\n",
    "print (dataf1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0194950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44a2263d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   TRAN_DATE    TRANAMOUNT     ACCOUNTNO           REFERENCENO  \\\n",
      "0           0  09-02-2022  3.192922e+08  0103SLMPSWDL  OTHERS-P SETT DT 01.   \n",
      "1           1  09-02-2022  1.565600e+02  0103SLMPSWDL  OTHERS-PSETTL DT 01.   \n",
      "2           2  09-02-2022  2.000000e+00  0103SLMPSWDL  OTHERS-PLPR - DT 01.   \n",
      "3           3  09-02-2022  4.872000e+05  0103SLMPSWDL  OTHERS-PMDU - DT 01.   \n",
      "4           4  09-02-2022  1.777348e+07  0103SLMPSWDL   OTHERS-PCI POS SETT   \n",
      "\n",
      "  TRAN_REMARKS    TRAN_ID  \n",
      "0          NaN  S85305249  \n",
      "1          NaN  S85305249  \n",
      "2          NaN  S85305249  \n",
      "3          NaN  S85305249  \n",
      "4          NaN  S85321543  \n"
     ]
    }
   ],
   "source": [
    "dataf2 = pd.read_csv(r'C:\\Users\\Dell\\Desktop\\New folder\\Test_1\\Test\\df2_out_SCLM.csv')\n",
    "print (dataf2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce1225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "1ec5ad2d",
   "metadata": {},
   "source": [
    "The isin() method checks if the Dataframe contains the specified value(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7503bfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "20    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf1.apply(tuple,1).isin(dataf2.apply(tuple,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0354f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "598e5804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, TRAN_DATE, TRAN_ID, TRAN_REMARKS, ACCOUNTNO, TRANAMOUNT, REFERENCENO]\n",
      "Index: [] \n",
      " 0.0059854984283447266 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = dataf1[dataf1.apply(tuple,1).isin(dataf2.apply(tuple,1))]\n",
    "end = time.time()\n",
    "print (result, '\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e50b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "387eb1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, TRAN_DATE, TRAN_ID, TRAN_REMARKS, ACCOUNTNO, TRANAMOUNT, REFERENCENO, _merge]\n",
      "Index: [] \n",
      " 0.02991938591003418 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result2 = dataf1.merge(dataf2, how= 'inner', indicator = True)\n",
    "end = time.time()\n",
    "print (result2,'\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677a1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7b2992d",
   "metadata": {},
   "source": [
    "# Merged data on TRAN_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d886f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0_x TRAN_DATE_x    TRAN_ID TRAN_REMARKS_x   ACCOUNTNO_x  \\\n",
      "0             0    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "1             0    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "2             0    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "3             0    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "4             0    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "5             1    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "6             1    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "7             1    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "8             1    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "9             1    9/2/2022  S85305249            NaN  0103SLMPSWDL   \n",
      "\n",
      "   TRANAMOUNT_x         REFERENCENO_x  Unnamed: 0_y TRAN_DATE_y  TRANAMOUNT_y  \\\n",
      "0 -3.192820e+08  OTHERS-P SETT DT01.0             0  09-02-2022  3.192922e+08   \n",
      "1 -3.192820e+08  OTHERS-P SETT DT01.0             1  09-02-2022  1.565600e+02   \n",
      "2 -3.192820e+08  OTHERS-P SETT DT01.0             2  09-02-2022  2.000000e+00   \n",
      "3 -3.192820e+08  OTHERS-P SETT DT01.0             3  09-02-2022  4.872000e+05   \n",
      "4 -3.192820e+08  OTHERS-P SETT DT01.0             7  09-02-2022  9.225900e+03   \n",
      "5 -4.042220e+03  OTHERS-P DIFF DT 31.             0  09-02-2022  3.192922e+08   \n",
      "6 -4.042220e+03  OTHERS-P DIFF DT 31.             1  09-02-2022  1.565600e+02   \n",
      "7 -4.042220e+03  OTHERS-P DIFF DT 31.             2  09-02-2022  2.000000e+00   \n",
      "8 -4.042220e+03  OTHERS-P DIFF DT 31.             3  09-02-2022  4.872000e+05   \n",
      "9 -4.042220e+03  OTHERS-P DIFF DT 31.             7  09-02-2022  9.225900e+03   \n",
      "\n",
      "    ACCOUNTNO_y         REFERENCENO_y TRAN_REMARKS_y  \n",
      "0  0103SLMPSWDL  OTHERS-P SETT DT 01.            NaN  \n",
      "1  0103SLMPSWDL  OTHERS-PSETTL DT 01.            NaN  \n",
      "2  0103SLMPSWDL  OTHERS-PLPR - DT 01.            NaN  \n",
      "3  0103SLMPSWDL  OTHERS-PMDU - DT 01.            NaN  \n",
      "4  0103SLMPSWDL  OTHERS-P DIFF DT 01.            NaN  \n",
      "5  0103SLMPSWDL  OTHERS-P SETT DT 01.            NaN  \n",
      "6  0103SLMPSWDL  OTHERS-PSETTL DT 01.            NaN  \n",
      "7  0103SLMPSWDL  OTHERS-PLPR - DT 01.            NaN  \n",
      "8  0103SLMPSWDL  OTHERS-PMDU - DT 01.            NaN  \n",
      "9  0103SLMPSWDL  OTHERS-P DIFF DT 01.            NaN   \n",
      " 0.05983448028564453 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_merge = dataf1.merge(dataf2, how = 'inner', left_on = \"TRAN_ID\", right_on = \"TRAN_ID\")\n",
    "end = time.time()\n",
    "print (data_merge.head(10),'\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841e2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "296db3e9",
   "metadata": {},
   "source": [
    "# Merged on TRAN_DATE,TRANAMOUNT & TRAN_ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccaf77d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0_x, TRAN_DATE, TRAN_ID, TRAN_REMARKS_x, ACCOUNTNO_x, TRANAMOUNT, REFERENCENO_x, Unnamed: 0_y, ACCOUNTNO_y, REFERENCENO_y, TRAN_REMARKS_y]\n",
      "Index: [] \n",
      " 0.008973836898803711 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result5 = pd.merge(dataf1,dataf2, on= ['TRAN_DATE', 'TRANAMOUNT', 'TRAN_ID'], how = 'inner')\n",
    "end = time.time()\n",
    "print (result5,'\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc3b5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "639d502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 TRAN_DATE    TRAN_ID               TRAN_REMARKS     ACCOUNTNO  \\\n",
      "0           0  9/2/2022  S85305249                        NaN  0103SLMPSWDL   \n",
      "1           1  9/2/2022  S85305249                        NaN  0103SLMPSWDL   \n",
      "2           2  9/2/2022  S88796439  224500032693//10101170199  0103SLMPSWDL   \n",
      "3           3  9/2/2022  S80939874                        NaN  0103SLMPSWDL   \n",
      "4           4  9/2/2022  S80939874                        NaN  0103SLMPSWDL   \n",
      "5           5  9/2/2022  S80939874                        NaN  0103SLMPSWDL   \n",
      "6           6  9/2/2022  S85290736                        NaN  0103SLMPSWDL   \n",
      "7           7  9/2/2022  S99485662                        NaN  0103SLMPSWDL   \n",
      "8           8  9/2/2022  S88797032  224500032711//10101170199  0103SLMPSWDL   \n",
      "9           9  9/2/2022  S85321543                        NaN  0103SLMPSWDL   \n",
      "\n",
      "     TRANAMOUNT           REFERENCENO  \n",
      "0 -3.192820e+08  OTHERS-P SETT DT01.0  \n",
      "1 -4.042220e+03  OTHERS-P DIFF DT 31.  \n",
      "2 -2.774900e+03                   NaN  \n",
      "3 -6.637716e+06                     -  \n",
      "4 -7.248358e+05                     -  \n",
      "5 -3.872458e+05                     -  \n",
      "6 -3.300000e+03               OTHERS-  \n",
      "7 -3.453200e+08                     -  \n",
      "8 -5.211500e+02                   NaN  \n",
      "9 -2.460642e+05  OTHERS-PMDU RVSL - D   \n",
      " 0.00498652458190918 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result5 = pd.concat([dataf1,dataf2], join=\"inner\")\n",
    "end = time.time()\n",
    "print (result5.head(10),'\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bd4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c80688a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0_x TRAN_DATE_x    TRAN_ID TRAN_REMARKS_x     ACCOUNTNO  \\\n",
      "0              3    9/2/2022  S80939874            NaN  0103SLMPSWDL   \n",
      "1              3    9/2/2022  S80939874            NaN  0103SLMPSWDL   \n",
      "2              3    9/2/2022  S80939874            NaN  0103SLMPSWDL   \n",
      "3              4    9/2/2022  S80939874            NaN  0103SLMPSWDL   \n",
      "4              4    9/2/2022  S80939874            NaN  0103SLMPSWDL   \n",
      "5              4    9/2/2022  S80939874            NaN  0103SLMPSWDL   \n",
      "6              5    9/2/2022  S80939874            NaN  0103SLMPSWDL   \n",
      "7              5    9/2/2022  S80939874            NaN  0103SLMPSWDL   \n",
      "8              5    9/2/2022  S80939874            NaN  0103SLMPSWDL   \n",
      "9             11    9/2/2022  S85321543            NaN  0103SLMPSWDL   \n",
      "10            13    9/2/2022  S85280052            NaN  0103SLMPSWDL   \n",
      "11            13    9/2/2022  S85280052            NaN  0103SLMPSWDL   \n",
      "12            14    9/2/2022  S85280052            NaN  0103SLMPSWDL   \n",
      "13            14    9/2/2022  S85280052            NaN  0103SLMPSWDL   \n",
      "\n",
      "    TRANAMOUNT_x           REFERENCENO  Unnamed: 0_y TRAN_DATE_y  \\\n",
      "0    -6637715.58                     -            10  09-02-2022   \n",
      "1    -6637715.58                     -            11  09-02-2022   \n",
      "2    -6637715.58                     -            12  09-02-2022   \n",
      "3     -724835.83                     -            10  09-02-2022   \n",
      "4     -724835.83                     -            11  09-02-2022   \n",
      "5     -724835.83                     -            12  09-02-2022   \n",
      "6     -387245.81                     -            10  09-02-2022   \n",
      "7     -387245.81                     -            11  09-02-2022   \n",
      "8     -387245.81                     -            12  09-02-2022   \n",
      "9   -17507099.77  OTHERS-PMCI USD (DIF            15  09-02-2022   \n",
      "10   -3274018.59               OTHERS-            22  09-02-2022   \n",
      "11   -3274018.59               OTHERS-            23  09-02-2022   \n",
      "12     -26486.20               OTHERS-            22  09-02-2022   \n",
      "13     -26486.20               OTHERS-            23  09-02-2022   \n",
      "\n",
      "    TRANAMOUNT_y TRAN_REMARKS_y  \n",
      "0   6.637716e+06            NaN  \n",
      "1   7.248358e+05            NaN  \n",
      "2   3.872458e+05            NaN  \n",
      "3   6.637716e+06            NaN  \n",
      "4   7.248358e+05            NaN  \n",
      "5   3.872458e+05            NaN  \n",
      "6   6.637716e+06            NaN  \n",
      "7   7.248358e+05            NaN  \n",
      "8   3.872458e+05            NaN  \n",
      "9   1.904099e+07            NaN  \n",
      "10  3.192820e+08            NaN  \n",
      "11  1.053284e+06            NaN  \n",
      "12  3.192820e+08            NaN  \n",
      "13  1.053284e+06            NaN   \n",
      " 0.011965036392211914 sec\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'merge_on_ref_acc_tran.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-674334d8d5a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresult3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresult3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'merge_on_ref_acc_tran.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'merge_on_ref_acc_tran.csv'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result3 = pd.merge(dataf1,dataf2, on= ['REFERENCENO', 'ACCOUNTNO','TRAN_ID'], how = 'inner')\n",
    "end = time.time()\n",
    "print (result3.head(20),'\\n',(end-start),'sec')\n",
    "result3 = dataf1.to_csv('merge_on_ref_acc_tran.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33b63a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0_x, TRAN_DATE_x, TRAN_ID_x, TRAN_REMARKS_x, ACCOUNTNO_x, TRANAMOUNT_x, REFERENCENO_x, Unnamed: 0_y, TRAN_DATE_y, TRANAMOUNT_y, ACCOUNTNO_y, REFERENCENO_y, TRAN_REMARKS_y, TRAN_ID_y, _merge]\n",
      "Index: [] \n",
      " 0.09207630157470703 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_merge1 = dataf1.merge(dataf2, how = 'inner', left_on = \"TRAN_ID\", right_on = \"TRAN_DATE\", validate= 'm:m', sort= True, indicator=True)\n",
    "end = time.time()\n",
    "print (data_merge1.head(10),'\\n',(end-start),'sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af2a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd281df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
